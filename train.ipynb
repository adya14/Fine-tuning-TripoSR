{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./envi/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./envi/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: filelock in ./envi/lib/python3.9/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: fsspec in ./envi/lib/python3.9/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./envi/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./envi/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./envi/lib/python3.9/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./envi/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./envi/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: sympy in ./envi/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./envi/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./envi/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./envi/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in ./envi/lib/python3.9/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: networkx in ./envi/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./envi/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: jinja2 in ./envi/lib/python3.9/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./envi/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./envi/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./envi/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./envi/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./envi/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/artificial-architecture/Desktop/TripoFT-adya/envi/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchsummary in ./envi/lib/python3.9/site-packages (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/artificial-architecture/Desktop/TripoFT-adya/envi/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/tatsy/torchmcubes.git (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 4))\n",
      "  Cloning https://github.com/tatsy/torchmcubes.git to /tmp/pip-req-build-oob0m3me\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tatsy/torchmcubes.git /tmp/pip-req-build-oob0m3me\n",
      "  Resolved https://github.com/tatsy/torchmcubes.git to commit 3aef8afa5f21b113afc4f4ea148baee850cbd472\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: omegaconf==2.3.0 in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: Pillow==10.1.0 in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 2)) (10.1.0)\n",
      "Requirement already satisfied: einops==0.7.0 in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: transformers==4.35.0 in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (4.35.0)\n",
      "Requirement already satisfied: trimesh==4.0.5 in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 6)) (4.0.5)\n",
      "Requirement already satisfied: rembg in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (2.0.56)\n",
      "Requirement already satisfied: huggingface-hub in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 8)) (0.17.3)\n",
      "Requirement already satisfied: imageio[ffmpeg] in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 9)) (2.34.1)\n",
      "Requirement already satisfied: gradio in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (4.8.0)\n",
      "Requirement already satisfied: xatlas==0.0.9 in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 11)) (0.0.9)\n",
      "Requirement already satisfied: moderngl==5.10.0 in ./envi/lib/python3.9/site-packages (from -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 12)) (5.10.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in ./envi/lib/python3.9/site-packages (from omegaconf==2.3.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./envi/lib/python3.9/site-packages (from omegaconf==2.3.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 1)) (4.9.3)\n",
      "Requirement already satisfied: requests in ./envi/lib/python3.9/site-packages (from transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./envi/lib/python3.9/site-packages (from transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./envi/lib/python3.9/site-packages (from transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (24.0)\n",
      "Requirement already satisfied: filelock in ./envi/lib/python3.9/site-packages (from transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (3.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./envi/lib/python3.9/site-packages (from transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (2024.5.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./envi/lib/python3.9/site-packages (from transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./envi/lib/python3.9/site-packages (from transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./envi/lib/python3.9/site-packages (from transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (0.14.1)\n",
      "Requirement already satisfied: glcontext<3,>=2.5.0 in ./envi/lib/python3.9/site-packages (from moderngl==5.10.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 12)) (2.5.0)\n",
      "Requirement already satisfied: opencv-python-headless in ./envi/lib/python3.9/site-packages (from rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (4.9.0.80)\n",
      "Requirement already satisfied: pooch in ./envi/lib/python3.9/site-packages (from rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (1.8.1)\n",
      "Requirement already satisfied: pymatting in ./envi/lib/python3.9/site-packages (from rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (1.1.12)\n",
      "Requirement already satisfied: scikit-image in ./envi/lib/python3.9/site-packages (from rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (0.22.0)\n",
      "Requirement already satisfied: scipy in ./envi/lib/python3.9/site-packages (from rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: onnxruntime in ./envi/lib/python3.9/site-packages (from rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (1.18.0)\n",
      "Requirement already satisfied: jsonschema in ./envi/lib/python3.9/site-packages (from rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (4.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./envi/lib/python3.9/site-packages (from huggingface-hub->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 8)) (4.11.0)\n",
      "Requirement already satisfied: fsspec in ./envi/lib/python3.9/site-packages (from huggingface-hub->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 8)) (2024.5.0)\n",
      "Requirement already satisfied: imageio-ffmpeg in ./envi/lib/python3.9/site-packages (from imageio[ffmpeg]->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 9)) (0.4.9)\n",
      "Requirement already satisfied: psutil in ./envi/lib/python3.9/site-packages (from imageio[ffmpeg]->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 9)) (5.9.8)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.12.0)\n",
      "Requirement already satisfied: matplotlib~=3.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (3.9.0)\n",
      "Requirement already satisfied: pydub in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.25.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: typer[all]<1.0,>=0.9 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.12.3)\n",
      "Requirement already satisfied: ffmpy in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.3.2)\n",
      "Requirement already satisfied: python-multipart in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.0.9)\n",
      "Requirement already satisfied: semantic-version~=2.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.10.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (6.4.0)\n",
      "Requirement already satisfied: orjson~=3.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (3.10.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (23.2.1)\n",
      "Requirement already satisfied: httpx in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.27.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.1.5)\n",
      "Requirement already satisfied: fastapi in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.29.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.7.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (5.3.0)\n",
      "Requirement already satisfied: jinja2<4.0 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (3.1.4)\n",
      "Requirement already satisfied: gradio-client==0.7.1 in ./envi/lib/python3.9/site-packages (from gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.7.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in ./envi/lib/python3.9/site-packages (from gradio-client==0.7.1->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (11.0.3)\n",
      "Requirement already satisfied: toolz in ./envi/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./envi/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (3.18.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./envi/lib/python3.9/site-packages (from jsonschema->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./envi/lib/python3.9/site-packages (from jsonschema->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./envi/lib/python3.9/site-packages (from jsonschema->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (0.18.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./envi/lib/python3.9/site-packages (from jsonschema->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (23.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./envi/lib/python3.9/site-packages (from matplotlib~=3.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (4.51.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./envi/lib/python3.9/site-packages (from matplotlib~=3.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./envi/lib/python3.9/site-packages (from matplotlib~=3.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./envi/lib/python3.9/site-packages (from matplotlib~=3.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./envi/lib/python3.9/site-packages (from matplotlib~=3.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./envi/lib/python3.9/site-packages (from matplotlib~=3.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (1.2.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./envi/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./envi/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2024.1)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in ./envi/lib/python3.9/site-packages (from pydantic>=2.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./envi/lib/python3.9/site-packages (from pydantic>=2.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./envi/lib/python3.9/site-packages (from requests->transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./envi/lib/python3.9/site-packages (from requests->transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./envi/lib/python3.9/site-packages (from requests->transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./envi/lib/python3.9/site-packages (from requests->transformers==4.35.0->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 5)) (3.7)\n",
      "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: rich>=10.11.0 in ./envi/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (13.7.1)\n",
      "Requirement already satisfied: click>=8.0.0 in ./envi/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./envi/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (1.5.4)\n",
      "Requirement already satisfied: h11>=0.8 in ./envi/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.14.0)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in ./envi/lib/python3.9/site-packages (from fastapi->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in ./envi/lib/python3.9/site-packages (from fastapi->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.1.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in ./envi/lib/python3.9/site-packages (from fastapi->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in ./envi/lib/python3.9/site-packages (from fastapi->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.0.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./envi/lib/python3.9/site-packages (from httpx->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./envi/lib/python3.9/site-packages (from httpx->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: anyio in ./envi/lib/python3.9/site-packages (from httpx->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (4.3.0)\n",
      "Requirement already satisfied: setuptools in ./envi/lib/python3.9/site-packages (from imageio-ffmpeg->imageio[ffmpeg]->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 9)) (58.1.0)\n",
      "Requirement already satisfied: coloredlogs in ./envi/lib/python3.9/site-packages (from onnxruntime->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (15.0.1)\n",
      "Requirement already satisfied: protobuf in ./envi/lib/python3.9/site-packages (from onnxruntime->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (5.26.1)\n",
      "Requirement already satisfied: flatbuffers in ./envi/lib/python3.9/site-packages (from onnxruntime->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (24.3.25)\n",
      "Requirement already satisfied: sympy in ./envi/lib/python3.9/site-packages (from onnxruntime->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (1.12)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./envi/lib/python3.9/site-packages (from pooch->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (4.2.2)\n",
      "Requirement already satisfied: numba!=0.49.0 in ./envi/lib/python3.9/site-packages (from pymatting->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (0.59.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./envi/lib/python3.9/site-packages (from scikit-image->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (2024.5.22)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in ./envi/lib/python3.9/site-packages (from scikit-image->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: networkx>=2.8 in ./envi/lib/python3.9/site-packages (from scikit-image->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (3.2.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./envi/lib/python3.9/site-packages (from email_validator>=2.0.0->fastapi->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.6.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in ./envi/lib/python3.9/site-packages (from numba!=0.49.0->pymatting->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (0.42.0)\n",
      "Requirement already satisfied: six>=1.5 in ./envi/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./envi/lib/python3.9/site-packages (from rich>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./envi/lib/python3.9/site-packages (from rich>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./envi/lib/python3.9/site-packages (from anyio->httpx->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (1.2.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in ./envi/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./envi/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.19.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./envi/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./envi/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.21.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./envi/lib/python3.9/site-packages (from coloredlogs->onnxruntime->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./envi/lib/python3.9/site-packages (from sympy->onnxruntime->rembg->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./envi/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt (line 10)) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/artificial-architecture/Desktop/TripoFT-adya/envi/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install torchsummary\n",
    "%pip install -r /home/artificial-architecture/Desktop/TripoFT-adya/TripoSR/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the TripoSR directory to the Python path\n",
    "sys.path.append(os.path.abspath('TripoSR'))\n",
    "\n",
    "# Import the TSR class\n",
    "from tsr.system import TSR\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artificial-architecture/Desktop/TripoFT-adya/envi/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/artificial-architecture/Desktop/TripoFT-adya/envi/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Add the TripoSR directory to the Python path\n",
    "sys.path.append(os.path.abspath('TripoSR'))\n",
    "\n",
    "# Import the TSR class\n",
    "from tsr.system import TSR\n",
    "\n",
    "# Load the configuration file\n",
    "config_path = 'TripoSR/config.yaml'\n",
    "cfg = OmegaConf.load(config_path)\n",
    "\n",
    "# Manually set `tokenizer.num_channels` before initializing other components\n",
    "cfg.backbone.in_channels = cfg.tokenizer.num_channels\n",
    "\n",
    "# Initialize the TSR model with the loaded and updated configuration\n",
    "model = TSR(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 33, 19, 33])\n",
      "torch.Size([1, 1, 33, 19, 33])\n"
     ]
    }
   ],
   "source": [
    "# # Move model to GPU 1\n",
    "# model = model.to(\"cuda:1\")import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class VoxelGridDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = [f for f in os.listdir(data_dir) if f.endswith('.npz')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
    "        data = np.load(file_path)\n",
    "        voxel_grid = data['voxel_grid']\n",
    "\n",
    "        # Convert to torch tensor\n",
    "        voxel_grid = torch.tensor(voxel_grid, dtype=torch.float32)\n",
    "\n",
    "        return voxel_grid\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # No need to pad since all voxel grids should be the same shape\n",
    "    voxel_grids = torch.stack(batch)\n",
    "    return voxel_grids\n",
    "\n",
    "def move_to_gpu(batch):\n",
    "    return batch.cuda()\n",
    "\n",
    "def main():\n",
    "    # Paths to your data directories\n",
    "    train_dir = '/home/artificial-architecture/Desktop/TripoFT-adya/split_data/train'\n",
    "    val_dir = '/home/artificial-architecture/Desktop/TripoFT-adya/split_data/val'\n",
    "    test_dir = '/home/artificial-architecture/Desktop/TripoFT-adya/split_data/test'\n",
    "\n",
    "    # Create dataset instances\n",
    "    train_dataset = VoxelGridDataset(train_dir)\n",
    "    val_dataset = VoxelGridDataset(val_dir)\n",
    "    test_dataset = VoxelGridDataset(test_dir)\n",
    "\n",
    "    # Create data loaders with custom collate function\n",
    "    batch_size = 1  # Adjust as needed\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=custom_collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=custom_collate_fn)\n",
    "\n",
    "    # Example of iterating through the train_loader\n",
    "    for voxel_grid in train_loader:\n",
    "        print(voxel_grid.shape)\n",
    "        # Move to GPU\n",
    "        voxel_grid = move_to_gpu(voxel_grid)\n",
    "        print(voxel_grid.shape)\n",
    "        # Add your training code here\n",
    "        break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# # Wrap the model with DataParallel to utilize GPU 1\n",
    "# model = nn.DataParallel(model, device_ids=[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 64, 32, 32, 32]           1,792\n",
      "            Conv3d-2       [-1, 64, 32, 32, 32]           1,792\n",
      "            Conv3d-3      [-1, 128, 32, 32, 32]         221,312\n",
      "            Conv3d-4      [-1, 128, 32, 32, 32]         221,312\n",
      "            Linear-5                 [-1, 3072]         789,504\n",
      "            Linear-6                 [-1, 3072]         789,504\n",
      "      ExampleModel-7              [-1, 1024, 3]               0\n",
      "      ExampleModel-8              [-1, 1024, 3]               0\n",
      "================================================================\n",
      "Total params: 2,025,216\n",
      "Trainable params: 2,025,216\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 96.09\n",
      "Params size (MB): 7.73\n",
      "Estimated Total Size (MB): 103.94\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Model Parameters:\n",
      "module.conv1.weight: torch.Size([64, 1, 3, 3, 3])\n",
      "module.conv1.bias: torch.Size([64])\n",
      "module.conv2.weight: torch.Size([128, 64, 3, 3, 3])\n",
      "module.conv2.bias: torch.Size([128])\n",
      "module.fc2.weight: torch.Size([3072, 256])\n",
      "module.fc2.bias: torch.Size([3072])\n",
      "Batch size: 1\n",
      "Epoch [1/20], Train Loss: 0.4721, Train Accuracy: 0.7011, Validation Loss: 0.4534, Training Time: 4229.29s, Gradient Norm: 43692.6333, Memory Allocated: 1.48GB, Memory Reserved: 21.20GB\n",
      "Batch size: 1\n",
      "Epoch [2/20], Train Loss: 0.4664, Train Accuracy: 0.7037, Validation Loss: 0.4474, Training Time: 4207.17s, Gradient Norm: 38538.0814, Memory Allocated: 7.21GB, Memory Reserved: 21.60GB\n",
      "Batch size: 1\n",
      "Epoch [3/20], Train Loss: 0.4606, Train Accuracy: 0.7066, Validation Loss: 0.4407, Training Time: 4208.86s, Gradient Norm: 40002.7884, Memory Allocated: 4.26GB, Memory Reserved: 21.46GB\n",
      "Batch size: 1\n",
      "Epoch [4/20], Train Loss: 0.4552, Train Accuracy: 0.7092, Validation Loss: 0.4350, Training Time: 4207.62s, Gradient Norm: 41097.7077, Memory Allocated: 5.06GB, Memory Reserved: 17.21GB\n",
      "Batch size: 1\n",
      "Epoch [5/20], Train Loss: 0.4492, Train Accuracy: 0.7123, Validation Loss: 0.4275, Training Time: 4209.20s, Gradient Norm: 35695.0157, Memory Allocated: 2.96GB, Memory Reserved: 21.20GB\n",
      "Batch size: 1\n",
      "Epoch [6/20], Train Loss: 0.4405, Train Accuracy: 0.7164, Validation Loss: 0.4186, Training Time: 4217.57s, Gradient Norm: 68791.1528, Memory Allocated: 3.08GB, Memory Reserved: 21.20GB\n",
      "Batch size: 1\n",
      "Epoch [7/20], Train Loss: 0.4291, Train Accuracy: 0.7220, Validation Loss: 0.4034, Training Time: 4218.86s, Gradient Norm: 139895.6759, Memory Allocated: 0.49GB, Memory Reserved: 17.21GB\n",
      "Batch size: 1\n",
      "Epoch [8/20], Train Loss: 0.4140, Train Accuracy: 0.7296, Validation Loss: 0.3874, Training Time: 4205.26s, Gradient Norm: 60741.5200, Memory Allocated: 2.02GB, Memory Reserved: 20.81GB\n",
      "Batch size: 1\n",
      "Epoch [9/20], Train Loss: 0.3957, Train Accuracy: 0.7380, Validation Loss: 0.3715, Training Time: 4204.82s, Gradient Norm: 18787.7106, Memory Allocated: 4.03GB, Memory Reserved: 20.00GB\n",
      "Batch size: 1\n",
      "Epoch [10/20], Train Loss: 0.3817, Train Accuracy: 0.7447, Validation Loss: 0.3578, Training Time: 4167.37s, Gradient Norm: 51937.5099, Memory Allocated: 1.00GB, Memory Reserved: 17.21GB\n",
      "Batch size: 1\n",
      "Epoch [11/20], Train Loss: 0.3690, Train Accuracy: 0.7509, Validation Loss: 0.3476, Training Time: 4168.57s, Gradient Norm: 182018.4968, Memory Allocated: 0.28GB, Memory Reserved: 21.08GB\n",
      "Batch size: 1\n",
      "Epoch [12/20], Train Loss: 0.3585, Train Accuracy: 0.7561, Validation Loss: 0.3383, Training Time: 4171.27s, Gradient Norm: 114157.7747, Memory Allocated: 1.97GB, Memory Reserved: 20.82GB\n",
      "Batch size: 1\n",
      "Epoch [13/20], Train Loss: 0.3480, Train Accuracy: 0.7614, Validation Loss: 0.3272, Training Time: 4177.48s, Gradient Norm: 107145.8052, Memory Allocated: 2.22GB, Memory Reserved: 21.46GB\n",
      "Batch size: 1\n",
      "Epoch [14/20], Train Loss: 0.3372, Train Accuracy: 0.7671, Validation Loss: 0.3161, Training Time: 4335.27s, Gradient Norm: 119643.5654, Memory Allocated: 0.93GB, Memory Reserved: 20.68GB\n",
      "Batch size: 1\n",
      "Epoch [15/20], Train Loss: 0.3268, Train Accuracy: 0.7726, Validation Loss: 0.3066, Training Time: 4414.10s, Gradient Norm: 112057.4293, Memory Allocated: 2.42GB, Memory Reserved: 17.21GB\n",
      "Batch size: 1\n",
      "Epoch [16/20], Train Loss: 0.3167, Train Accuracy: 0.7778, Validation Loss: 0.2969, Training Time: 4637.69s, Gradient Norm: 114188.4659, Memory Allocated: 3.58GB, Memory Reserved: 17.21GB\n",
      "Batch size: 1\n",
      "Epoch [17/20], Train Loss: 0.3074, Train Accuracy: 0.7828, Validation Loss: 0.2882, Training Time: 4480.22s, Gradient Norm: 97923.7793, Memory Allocated: 2.57GB, Memory Reserved: 21.33GB\n",
      "Batch size: 1\n",
      "Epoch [18/20], Train Loss: 0.2992, Train Accuracy: 0.7874, Validation Loss: 0.2801, Training Time: 4530.39s, Gradient Norm: 103470.3700, Memory Allocated: 1.97GB, Memory Reserved: 21.20GB\n",
      "Batch size: 1\n",
      "Epoch [19/20], Train Loss: 0.2900, Train Accuracy: 0.7925, Validation Loss: 0.2702, Training Time: 4432.22s, Gradient Norm: 98040.2222, Memory Allocated: 1.77GB, Memory Reserved: 19.96GB\n",
      "Batch size: 1\n",
      "Epoch [20/20], Train Loss: 0.2797, Train Accuracy: 0.7984, Validation Loss: 0.2607, Training Time: 4288.33s, Gradient Norm: 95531.9653, Memory Allocated: 6.28GB, Memory Reserved: 21.20GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time  # To measure training time per epoch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "\n",
    "# Define a loss function using Chamfer Distance\n",
    "class ChamferDistance(nn.Module):\n",
    "    def forward(self, points1, points2):\n",
    "        points1 = points1.float()\n",
    "        points2 = points2.float()\n",
    "        batch_size, num_points, _ = points1.size()\n",
    "        dist1 = torch.cdist(points1, points2)\n",
    "        dist2 = torch.cdist(points2, points1)\n",
    "        loss1 = dist1.min(dim=2)[0].mean(dim=1)\n",
    "        loss2 = dist2.min(dim=2)[0].mean(dim=1)\n",
    "        loss = (loss1 + loss2).mean()\n",
    "        return loss\n",
    "\n",
    "loss_fn = ChamferDistance()\n",
    "\n",
    "class ExampleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExampleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = None  # Initialize fc1 as None\n",
    "        self.fc2 = nn.Linear(256, 1024 * 3)  # Adjust to output a batch of 1024 points (each with 3 coordinates)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.fc1 is None:\n",
    "            flattened_size = x.size(1)\n",
    "            self.fc1 = nn.Linear(flattened_size, 256)\n",
    "            self.fc1.to(x.device)  # Ensure the new layer is on the correct device\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1, 1024, 3)  # Reshape to [batch_size, num_points, 3]\n",
    "        return x\n",
    "\n",
    "# Function to transform model output to point cloud\n",
    "def transform_output_to_point_cloud(output):\n",
    "    return output\n",
    "\n",
    "# Wrapper function to handle model call with device\n",
    "def call_model_with_device(model, vertices, device):\n",
    "    return model(vertices.to(device))\n",
    "\n",
    "# Function to calculate validation metrics\n",
    "def validate(model, val_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for voxel_grid in val_loader:\n",
    "            voxel_grid = voxel_grid.to(device)\n",
    "            voxel_grid_points = voxel_grid.view(voxel_grid.size(0), -1, 3)\n",
    "            model_output = call_model_with_device(model, voxel_grid, device)\n",
    "            outputs = transform_output_to_point_cloud(model_output)\n",
    "            loss = loss_fn(outputs, voxel_grid_points)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    return avg_val_loss\n",
    "\n",
    "# Function to calculate training accuracy\n",
    "def calculate_accuracy(outputs, voxel_grid_points):\n",
    "    chamfer_dist = ChamferDistance()\n",
    "    outputs = outputs.float()\n",
    "    voxel_grid_points = voxel_grid_points.float()\n",
    "    accuracy = 1 / (1 + chamfer_dist(outputs, voxel_grid_points).item())\n",
    "    return accuracy\n",
    "\n",
    "# Training function with gradient accumulation, mixed precision, and early stopping\n",
    "def train(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, device, accumulation_steps=4, patience=3):\n",
    "    scaler = GradScaler()  # For mixed precision\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0  # Initialize running accuracy\n",
    "\n",
    "        print(f\"Batch size: {train_loader.batch_size}\")  # Print batch size at the beginning of the epoch\n",
    "\n",
    "        for i, voxel_grid in enumerate(train_loader):\n",
    "            voxel_grid = voxel_grid.to(device)\n",
    "            voxel_grid_points = voxel_grid.view(voxel_grid.size(0), -1, 3)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():  # Mixed precision context\n",
    "                model_output = call_model_with_device(model, voxel_grid, device)  # Call model with device argument\n",
    "                outputs = transform_output_to_point_cloud(model_output)  # Transform to point cloud\n",
    "                loss = loss_fn(outputs, voxel_grid_points)\n",
    "                loss = loss / accumulation_steps  # Normalize the loss\n",
    "\n",
    "            scaler.scale(loss).backward()  # Scaled loss backward\n",
    "\n",
    "            if (i + 1) % accumulation_steps == 0:  # Perform step every accumulation_steps\n",
    "                scaler.step(optimizer)  # Optimizer step\n",
    "                scaler.update()  # Update scaler\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * accumulation_steps  # Adjust running loss\n",
    "            running_accuracy += calculate_accuracy(outputs, voxel_grid_points)  # Accumulate accuracy\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_train_accuracy = running_accuracy / len(train_loader)  # Average accuracy\n",
    "\n",
    "        # Validation step\n",
    "        avg_val_loss = validate(model, val_loader, loss_fn, device)\n",
    "\n",
    "        # Gradient norm calculation\n",
    "        total_norm = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                param_norm = p.grad.data.norm(2)\n",
    "                total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** 0.5\n",
    "\n",
    "        # Memory usage\n",
    "        memory_allocated = torch.cuda.memory_allocated(device) / (1024 ** 3)  # Convert to GB\n",
    "        memory_reserved = torch.cuda.memory_reserved(device) / (1024 ** 3)  # Convert to GB\n",
    "\n",
    "        # Time per epoch\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Train Accuracy: {avg_train_accuracy:.4f}, '  # Print training accuracy\n",
    "              f'Validation Loss: {avg_val_loss:.4f}, '\n",
    "              f'Training Time: {epoch_time:.2f}s, '\n",
    "              f'Gradient Norm: {total_norm:.4f}, '\n",
    "              f'Memory Allocated: {memory_allocated:.2f}GB, '\n",
    "              f'Memory Reserved: {memory_reserved:.2f}GB')\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 3  # Reset patience counter\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        # Clear unused variables and cache\n",
    "        del voxel_grid, outputs, loss, model_output\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "class VoxelGridDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = [f for f in os.listdir(data_dir) if f.endswith('.npz')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
    "        data = np.load(file_path)\n",
    "        voxel_grid = data['voxel_grid']\n",
    "        voxel_grid = torch.tensor(voxel_grid, dtype=torch.float32)\n",
    "        return voxel_grid\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    voxel_grids = torch.stack(batch)\n",
    "    return voxel_grids\n",
    "\n",
    "def move_to_gpu(batch):\n",
    "    return batch.cuda()\n",
    "\n",
    "def main():\n",
    "    # Paths to your data directories\n",
    "    train_dir = '/home/artificial-architecture/Desktop/TripoFT-adya/split_data/train'\n",
    "    val_dir = '/home/artificial-architecture/Desktop/TripoFT-adya/split_data/val'\n",
    "    test_dir = '/home/artificial-architecture/Desktop/TripoFT-adya/split_data/test'\n",
    "\n",
    "    # Create dataset instances\n",
    "    train_dataset = VoxelGridDataset(train_dir)\n",
    "    val_dataset = VoxelGridDataset(val_dir)\n",
    "    test_dataset = VoxelGridDataset(test_dir)\n",
    "\n",
    "    # Create data loaders with custom collate function\n",
    "    batch_size = 1  # Adjust as needed\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=custom_collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=custom_collate_fn)\n",
    "\n",
    "    # Move model to GPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ExampleModel().to(device)\n",
    "\n",
    "    # Wrap the model with DataParallel to utilize multiple GPUs\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "\n",
    "    # Print the model summary\n",
    "    print(\"Model Summary:\")\n",
    "    summary(model, (1, 32, 32, 32))  # Assuming the input size is (1, 32, 32, 32), adjust as needed\n",
    "\n",
    "    # Print all model parameters\n",
    "    print(\"\\nModel Parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"{name}: {param.shape}\")\n",
    "\n",
    "    # Define an optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adjust learning rate as needed\n",
    "\n",
    "    # Define the number of epochs\n",
    "    num_epochs = 20  # Adjust as needed\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    train(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 64, 32, 32, 32]           1,792\n",
      "            Conv3d-2       [-1, 64, 32, 32, 32]           1,792\n",
      "            Conv3d-3      [-1, 128, 32, 32, 32]         221,312\n",
      "            Conv3d-4      [-1, 128, 32, 32, 32]         221,312\n",
      "            Linear-5                 [-1, 3072]         789,504\n",
      "      ExampleModel-6              [-1, 1024, 3]               0\n",
      "            Linear-7                 [-1, 3072]         789,504\n",
      "      ExampleModel-8              [-1, 1024, 3]               0\n",
      "================================================================\n",
      "Total params: 2,025,216\n",
      "Trainable params: 2,025,216\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 96.09\n",
      "Params size (MB): 7.73\n",
      "Estimated Total Size (MB): 103.94\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Model Parameters:\n",
      "module.conv1.weight: torch.Size([64, 1, 3, 3, 3])\n",
      "module.conv1.bias: torch.Size([64])\n",
      "module.conv2.weight: torch.Size([128, 64, 3, 3, 3])\n",
      "module.conv2.bias: torch.Size([128])\n",
      "module.fc2.weight: torch.Size([3072, 256])\n",
      "module.fc2.bias: torch.Size([3072])\n",
      "Epoch 1/10 - Test Loss: 0.4495, Test Accuracy: 0.7100\n",
      "Epoch 2/10 - Test Loss: 0.4498, Test Accuracy: 0.7098\n",
      "Epoch 3/10 - Test Loss: 0.4497, Test Accuracy: 0.7099\n",
      "Epoch 4/10 - Test Loss: 0.4500, Test Accuracy: 0.7098\n",
      "Epoch 5/10 - Test Loss: 0.4504, Test Accuracy: 0.7095\n",
      "Epoch 6/10 - Test Loss: 0.4496, Test Accuracy: 0.7098\n",
      "Epoch 7/10 - Test Loss: 0.4497, Test Accuracy: 0.7098\n",
      "Epoch 8/10 - Test Loss: 0.4496, Test Accuracy: 0.7098\n",
      "Epoch 9/10 - Test Loss: 0.4497, Test Accuracy: 0.7098\n",
      "Epoch 10/10 - Test Loss: 0.4503, Test Accuracy: 0.7096\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "# Define a loss function using Chamfer Distance\n",
    "class ChamferDistance(nn.Module):\n",
    "    def forward(self, points1, points2):\n",
    "        points1 = points1.float()\n",
    "        points2 = points2.float()\n",
    "        batch_size, num_points, _ = points1.size()\n",
    "        dist1 = torch.cdist(points1, points2)\n",
    "        dist2 = torch.cdist(points2, points1)\n",
    "        loss1 = dist1.min(dim=2)[0].mean(dim=1)\n",
    "        loss2 = dist2.min(dim=2)[0].mean(dim=1)\n",
    "        loss = (loss1 + loss2).mean()\n",
    "        return loss\n",
    "\n",
    "loss_fn = ChamferDistance()\n",
    "\n",
    "class ExampleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExampleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = None  # Initialize fc1 as None\n",
    "        self.fc2 = nn.Linear(256, 1024 * 3)  # Adjust to output a batch of 1024 points (each with 3 coordinates)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if self.fc1 is None:\n",
    "            flattened_size = x.size(1)\n",
    "            self.fc1 = nn.Linear(flattened_size, 256)\n",
    "            self.fc1.to(x.device)  # Ensure the new layer is on the correct device\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1, 1024, 3)  # Reshape to [batch_size, num_points, 3]\n",
    "        return x\n",
    "\n",
    "# Function to transform model output to point cloud\n",
    "def transform_output_to_point_cloud(output):\n",
    "    return output\n",
    "\n",
    "# Wrapper function to handle model call with device\n",
    "def call_model_with_device(model, vertices, device):\n",
    "    return model(vertices.to(device))\n",
    "\n",
    "# Testing function\n",
    "def test(model, test_loader, loss_fn, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for voxel_grid in test_loader:\n",
    "                voxel_grid = voxel_grid.to(device)\n",
    "                voxel_grid_points = voxel_grid.view(voxel_grid.size(0), -1, 3)  # Reshape voxel_grid to [batch_size, num_points, 3]\n",
    "\n",
    "                model_output = call_model_with_device(model, voxel_grid, device)\n",
    "                outputs = transform_output_to_point_cloud(model_output)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = loss_fn(outputs, voxel_grid_points)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy = calculate_accuracy(outputs, voxel_grid_points)\n",
    "                test_accuracy += accuracy\n",
    "\n",
    "            test_loss /= len(test_loader)\n",
    "            test_accuracy /= len(test_loader)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(outputs, voxel_grid_points):\n",
    "    chamfer_dist = ChamferDistance()\n",
    "    outputs = outputs.float()\n",
    "    voxel_grid_points = voxel_grid_points.float()\n",
    "    accuracy = 1 / (1 + chamfer_dist(outputs, voxel_grid_points).item())\n",
    "    return accuracy\n",
    "\n",
    "class VoxelGridDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.files = [f for f in os.listdir(data_dir) if f.endswith('.npz')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
    "        data = np.load(file_path)\n",
    "        voxel_grid = data['voxel_grid']\n",
    "        voxel_grid = torch.tensor(voxel_grid, dtype=torch.float32)\n",
    "        return voxel_grid\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    voxel_grids = torch.stack(batch)\n",
    "    return voxel_grids\n",
    "\n",
    "def main():\n",
    "    # Paths to your data directories\n",
    "    test_dir = '/home/artificial-architecture/Desktop/TripoFT-adya/split_data/test'\n",
    "\n",
    "    # Create dataset instance\n",
    "    test_dataset = VoxelGridDataset(test_dir)\n",
    "\n",
    "    # Create data loader with custom collate function\n",
    "    batch_size = 1  # Adjust as needed\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=custom_collate_fn)\n",
    "\n",
    "    # Move model to GPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ExampleModel().to(device)\n",
    "\n",
    "    # Wrap the model with DataParallel to utilize multiple GPUs\n",
    "    model = nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "\n",
    "    # Print the model summary\n",
    "    print(\"Model Summary:\")\n",
    "    summary(model, (1, 32, 32, 32))  # Assuming the input size is (1, 32, 32, 32), adjust as needed\n",
    "\n",
    "    # Print all model parameters\n",
    "    print(\"\\nModel Parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"{name}: {param.shape}\")\n",
    "\n",
    "    # Test the model for a specified number of epochs\n",
    "    test(model, test_loader, loss_fn, device, num_epochs=10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
