{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./myenv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in ./myenv/lib/python3.10/site-packages (0.18.0)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.10/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: sympy in ./myenv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./myenv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./myenv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./myenv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.3.0 in ./myenv/lib/python3.10/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./myenv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./myenv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./myenv/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./myenv/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./myenv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./myenv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./myenv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./myenv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./myenv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./myenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./myenv/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: trimesh in ./myenv/lib/python3.10/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy in ./myenv/lib/python3.10/site-packages (1.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision\n",
    "%pip install trimesh numpy scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import json\n",
    "import trimesh\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/aalab/Desktop/tripoFT/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first few rows of the DataFrame:\n",
      "                                 filename      size  \\\n",
      "0  cadbury_dairy_milk_chocolate_piece.glb    152796   \n",
      "1          bonnie_melted_chocolate_ar.glb   8285860   \n",
      "2              chocobar_ice_cream (1).glb   4499300   \n",
      "3                           ice_cream.glb  12444648   \n",
      "4                   chocolate_truffle.glb   2084100   \n",
      "\n",
      "                                         object_path  \n",
      "0  /home/aalab/Desktop/tripoFT/Dataset/cadbury_da...  \n",
      "1  /home/aalab/Desktop/tripoFT/Dataset/bonnie_mel...  \n",
      "2  /home/aalab/Desktop/tripoFT/Dataset/chocobar_i...  \n",
      "3  /home/aalab/Desktop/tripoFT/Dataset/ice_cream.glb  \n",
      "4  /home/aalab/Desktop/tripoFT/Dataset/chocolate_...  \n",
      "\n",
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145 entries, 0 to 144\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   filename     145 non-null    object\n",
      " 1   size         145 non-null    int64 \n",
      " 2   object_path  145 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.5+ KB\n",
      "None\n",
      "\n",
      "Data columns:\n",
      "Index(['filename', 'size', 'object_path'], dtype='object')\n",
      "\n",
      "Data described:\n",
      "               size\n",
      "count  1.450000e+02\n",
      "mean   1.302109e+07\n",
      "std    2.178698e+07\n",
      "min    1.987600e+04\n",
      "25%    1.708740e+06\n",
      "50%    5.081284e+06\n",
      "75%    1.750160e+07\n",
      "max    1.431980e+08\n"
     ]
    }
   ],
   "source": [
    "print(\"The first few rows of the DataFrame:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nData info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nData columns:\")\n",
    "print(data.columns)\n",
    "\n",
    "print(\"\\nData described:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   filename      size  \\\n",
      "0    cadbury_dairy_milk_chocolate_piece.glb    152796   \n",
      "1            bonnie_melted_chocolate_ar.glb   8285860   \n",
      "2                chocobar_ice_cream (1).glb   4499300   \n",
      "3                             ice_cream.glb  12444648   \n",
      "4                     chocolate_truffle.glb   2084100   \n",
      "..                                      ...       ...   \n",
      "140                     strawberry_cake.glb  25159596   \n",
      "141                jiggly_bunny_pudding.glb   1026416   \n",
      "142            kitchen_sink_fiesta_5149.glb  26103980   \n",
      "143   easter_egg_2024_marbled_chocolate.glb   3743544   \n",
      "144              paleta_payaso_lollypop.glb    439920   \n",
      "\n",
      "                                           object_path  \n",
      "0    /home/aalab/Desktop/tripoFT/Dataset/cadbury_da...  \n",
      "1    /home/aalab/Desktop/tripoFT/Dataset/bonnie_mel...  \n",
      "2    /home/aalab/Desktop/tripoFT/Dataset/chocobar_i...  \n",
      "3    /home/aalab/Desktop/tripoFT/Dataset/ice_cream.glb  \n",
      "4    /home/aalab/Desktop/tripoFT/Dataset/chocolate_...  \n",
      "..                                                 ...  \n",
      "140  /home/aalab/Desktop/tripoFT/Dataset/strawberry...  \n",
      "141  /home/aalab/Desktop/tripoFT/Dataset/jiggly_bun...  \n",
      "142  /home/aalab/Desktop/tripoFT/Dataset/kitchen_si...  \n",
      "143  /home/aalab/Desktop/tripoFT/Dataset/easter_egg...  \n",
      "144  /home/aalab/Desktop/tripoFT/Dataset/paleta_pay...  \n",
      "\n",
      "[145 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop rows with missing values in specific columns\n",
    "columns_with_missing_values = ['filename', 'size', 'object_path']\n",
    "data.dropna(subset=columns_with_missing_values, inplace=True)\n",
    "\n",
    "# Convert columns to appropriate data types\n",
    "data['filename'] = data['filename'].astype(str)\n",
    "data['size'] = data['size'].astype(str)\n",
    "data['object_path'] = data['object_path'].astype(str)\n",
    "\n",
    "# Print cleaned DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert 3D Objects into a Usable Format that our model can work with, such as voxel grids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cadbury_dairy_milk_chocolate_piece.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/bonnie_melted_chocolate_ar.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocobar_ice_cream (1).glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/ice_cream.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_truffle.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/oreo.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/heart_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/candy_vending_machine.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/gummy_bear_bull.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/valentines_heart.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/beardpapas_smores_puff__scan.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/doughnut_pack.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cc0_-_candies.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/biscuit.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/hot_fudge_warmer.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_milkshake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/vegan_icecream.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/power_shake_chocolate.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/adidas_chocolate_to_my_strawberry_sneaker.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/ferrero_rocher.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/ice_cream_sandwich.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/blue_mm_without_eyes (1).glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/worlds_last_choco_taco.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_python.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/krispy_kreme_twix_bar_doughnut.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/christmas_cookie_.rawscan..glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/lindt_gold_easter_bunny.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/fluid_simulation.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/ice-cream.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/candy_tractor.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/free_to_download_handpainted_stylized_cupcake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/paper_cup_perfect.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_muffin.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_waffles.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/banana_yellow_low_poly_asset.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_cake (1).glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/walshbear.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_dessert.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/s00002_brownie_2.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/the_simpsons_game_2007_-_chocolate_bunny.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cup_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/strawberry_cake_low_poly.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolates_etagere_-_decoration.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/sundae_-_sketchfab_low_poly_challenge_desserts.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cookies_3dst6.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/sugar_bunny_in_choco.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/kinder_surprise_egg.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/gummy_bear (1).glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_berry_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/hugs_kisses__cookies.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cupcake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_donut_3d_scan_free.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/saint_nicholas_boot.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/hershey_chocolate_syrup.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/italian_chocolates.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/florentiner.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/hazelnut_twist.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_mini_cookies.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cutie_cupcake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/happy_easter_chocolate_bunny.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_starbucks_muffin.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/harry_potter_official_chocolate_frog_box.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/sliced_marble_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/jelly.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/break_3december_day_19.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/mobile_-_gummy_bear_runner_-_santa_hat.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/melting_heart.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/pink_donut_with_sprinkles.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/gummy_bear_gummibar_model.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/gummy_bear (2).glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/mug-o-otterlatte.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/disco_gummy_bear.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/dreamy_chocolate_surprise.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_mousse_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/simple_chocolate_bar.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_bars.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/schokokuchen_lina_2024.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolates.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/low-poly_chocolate_bar.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/tim_tam.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/nestle_crunch_bar.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/lava_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/a_little_bite_of_france..glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/sofa.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/18th_century_chocolate_bar.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_frog.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/dark_chocolate_syrup.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/milkshake_my_friend.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/long_donut.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/hazelnuts_chocolate_bar.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocobar_ice_cream.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/blue_mm_without_eyes.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/ketchup.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cannoli.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/hot_chocolate_with_whipped_cream.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/photorealistic_chocolate_milk_carton_pint.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/metamorphosis_chocolate_-_wavy.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/easter_bunny_cupcake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/coffee_crisp.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/birthday_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_cupcake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_easter_bunny.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/brownie_square.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cake_gradient.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_cookies.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/kawai_ice-cream.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_donut.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/white_chocolate_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/ferrero_rocher__chocolate.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_hedgehog.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_easter_bunny (1).glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/the_meadows_arctic_swirl_frozen_custard_dessert.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_buttercream_cupcake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/valentines_chocolate_heart.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/ice_cream (1).glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/pancakes_low_poly_model.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_muffin_game_ready__2k_pbr.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/nesquik_chocolate_milk.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/paleta_payaso.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/lindt_gold_chocolate_bunny.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/donut.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/low_poly_chocolate_bar.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/pastry_bear.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/candy_crush_bomba_de_color.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/gummy_bears.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_cocktail.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_boy.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_muffin_school_project.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/nutella_jar_of_chocolate.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_pie.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/3december_choco_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/ice_cream_in_marble_bowl.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/gummy_bear.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/chocolate_teddy_bear.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/lcm_rice_crispy_treat.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/hershey_kiss.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/hot_chocolate.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/strawberry_cake.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/jiggly_bunny_pudding.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/kitchen_sink_fiesta_5149.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/easter_egg_2024_marbled_chocolate.glb\n",
      "Processing /home/aalab/Desktop/tripoFT/Dataset/paleta_payaso_lollypop.glb\n",
      "Conversion complete.\n"
     ]
    }
   ],
   "source": [
    "input_directory = '/home/aalab/Desktop/tripoFT/Dataset'\n",
    "output_directory = '/home/aalab/Desktop/tripoFT/tensors'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Function to process and save a single .glb file\n",
    "def process_glb_file(file_path, output_dir):\n",
    "    # Load the .glb file\n",
    "    scene = trimesh.load(file_path)\n",
    "    \n",
    "    # Check if the loaded object is a Scene or a single Mesh\n",
    "    if isinstance(scene, trimesh.Scene):\n",
    "        meshes = scene.geometry.values()\n",
    "    else:\n",
    "        meshes = [scene]\n",
    "\n",
    "    for i, mesh in enumerate(meshes):\n",
    "        # Extract vertices and faces\n",
    "        vertices = mesh.vertices\n",
    "        faces = mesh.faces\n",
    "        \n",
    "        # Convert to tensors\n",
    "        vertices_tensor = torch.tensor(vertices, dtype=torch.float32)\n",
    "        faces_tensor = torch.tensor(faces, dtype=torch.int64)\n",
    "        \n",
    "        # Create file base name without extension and append index for multiple meshes\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        mesh_suffix = f'_{i}' if len(meshes) > 1 else ''\n",
    "        \n",
    "        # Save tensors to files\n",
    "        torch.save(vertices_tensor, os.path.join(output_dir, f'{base_name}{mesh_suffix}_vertices.pt'))\n",
    "        torch.save(faces_tensor, os.path.join(output_dir, f'{base_name}{mesh_suffix}_faces.pt'))\n",
    "\n",
    "# Iterate over all .glb files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.glb'):\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        print(f'Processing {file_path}')\n",
    "        process_glb_file(file_path, output_directory)\n",
    "\n",
    "print('Conversion complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into train, validation, and test sets.\n",
      "6432 4502 964\n"
     ]
    }
   ],
   "source": [
    "tensor_directory = '/home/aalab/Desktop/tripoFT/tensors'\n",
    "\n",
    "# Directory to save the splits\n",
    "train_dir = '/home/aalab/Desktop/tripoFT/split_data/train'\n",
    "val_dir = '/home/aalab/Desktop/tripoFT/split_data/val'\n",
    "test_dir = '/home/aalab/Desktop/tripoFT/split_data/test'\n",
    "\n",
    "# # Create directories if they don't exist\n",
    "for directory in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# List of voxel tensor files\n",
    "tensor_files = os.listdir(tensor_directory)\n",
    "random.shuffle(tensor_files)\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Calculate the number of files for each split\n",
    "num_files = len(tensor_files)\n",
    "num_train = int(train_ratio * num_files)\n",
    "num_val = int(val_ratio * num_files)\n",
    "\n",
    "# Split the files\n",
    "train_files = tensor_files[:num_train]\n",
    "val_files = tensor_files[num_train:num_train + num_val]\n",
    "test_files = tensor_files[num_train + num_val:]\n",
    "\n",
    "# Move files to respective directories\n",
    "for file in train_files:\n",
    "    shutil.move(os.path.join(tensor_directory, file), os.path.join(train_dir, file))\n",
    "\n",
    "for file in val_files:\n",
    "    shutil.move(os.path.join(tensor_directory, file), os.path.join(val_dir, file))\n",
    "\n",
    "for file in test_files:\n",
    "    shutil.move(os.path.join(tensor_directory, file), os.path.join(test_dir, file))\n",
    "\n",
    "print(\"Data split into train, validation, and test sets.\")\n",
    "print(num_files, num_train, num_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CombinedTensorDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Directory with all the combined tensor files.\n",
    "        \"\"\"\n",
    "        self.tensor_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.pt')])\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.tensor_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (vertices, faces) where vertices is the tensor of vertices and faces is the tensor of faces.\n",
    "        \"\"\"\n",
    "        tensor_path = os.path.join(self.data_dir, self.tensor_files[idx])\n",
    "        \n",
    "        # Load the combined tensor file\n",
    "        combined_tensor = torch.load(tensor_path)\n",
    "        \n",
    "        # Assuming the combined tensor is a tuple (vertices, faces)\n",
    "        vertices, faces = combined_tensor\n",
    "        \n",
    "        return vertices, faces\n",
    "\n",
    "# Directories containing your combined tensor files\n",
    "train_data_dir = '/home/aalab/Desktop/tripoFT/split_data/train'\n",
    "val_data_dir = '/home/aalab/Desktop/tripoFT/split_data/val'\n",
    "test_data_dir = '/home/aalab/Desktop/tripoFT/split_data/test'\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = CombinedTensorDataset(train_data_dir)\n",
    "val_dataset = CombinedTensorDataset(val_data_dir)\n",
    "test_dataset = CombinedTensorDataset(test_data_dir)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the TripoSR Model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the TripoSR directory to the Python path\n",
    "sys.path.append(os.path.abspath('TripoSR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tatsy/torchmcubes.git (from -r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 4))\n",
      "  Cloning https://github.com/tatsy/torchmcubes.git to /tmp/pip-req-build-2poytg1o\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tatsy/torchmcubes.git /tmp/pip-req-build-2poytg1o\n",
      "  Resolved https://github.com/tatsy/torchmcubes.git to commit 3aef8afa5f21b113afc4f4ea148baee850cbd472\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: omegaconf==2.3.0 in ./myenv/lib/python3.10/site-packages (from -r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 1)) (2.3.0)\n",
      "Collecting Pillow==10.1.0\n",
      "  Using cached Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "Collecting einops==0.7.0\n",
      "  Using cached einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Collecting transformers==4.35.0\n",
      "  Using cached transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
      "Collecting trimesh==4.0.5\n",
      "  Using cached trimesh-4.0.5-py3-none-any.whl (688 kB)\n",
      "Collecting rembg\n",
      "  Using cached rembg-2.0.56-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: huggingface-hub in ./myenv/lib/python3.10/site-packages (from -r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 8)) (0.23.0)\n",
      "Collecting imageio[ffmpeg]\n",
      "  Using cached imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "Collecting gradio\n",
      "  Downloading gradio-4.31.3-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.9.* in ./myenv/lib/python3.10/site-packages (from omegaconf==2.3.0->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 1)) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in ./myenv/lib/python3.10/site-packages (from omegaconf==2.3.0->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 1)) (6.0.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./myenv/lib/python3.10/site-packages (from transformers==4.35.0->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.10/site-packages (from transformers==4.35.0->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./myenv/lib/python3.10/site-packages (from transformers==4.35.0->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 5)) (4.66.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.10/site-packages (from transformers==4.35.0->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 5)) (24.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.15,>=0.14\n",
      "  Using cached tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.10/site-packages (from transformers==4.35.0->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 5)) (3.14.0)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "Collecting pooch\n",
      "  Using cached pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: scipy in ./myenv/lib/python3.10/site-packages (from rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (1.13.0)\n",
      "Collecting pymatting\n",
      "  Using cached PyMatting-1.1.12-py3-none-any.whl (52 kB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-image\n",
      "  Using cached scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "Requirement already satisfied: jsonschema in ./myenv/lib/python3.10/site-packages (from rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (4.22.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./myenv/lib/python3.10/site-packages (from huggingface-hub->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 8)) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./myenv/lib/python3.10/site-packages (from huggingface-hub->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 8)) (4.11.0)\n",
      "Requirement already satisfied: psutil in ./myenv/lib/python3.10/site-packages (from imageio[ffmpeg]->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 9)) (5.9.8)\n",
      "Collecting imageio-ffmpeg\n",
      "  Using cached imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "Collecting python-multipart>=0.0.9\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Collecting gradio-client==0.16.3\n",
      "  Downloading gradio_client-0.16.3-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting semantic-version~=2.0\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in ./myenv/lib/python3.10/site-packages (from gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (2.1.5)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting altair<6.0,>=4.2.0\n",
      "  Using cached altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "Collecting pydantic>=2.0\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3~=2.0 in ./myenv/lib/python3.10/site-packages (from gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (2.2.1)\n",
      "Collecting orjson~=3.0\n",
      "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx>=0.24.1\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Collecting aiofiles<24.0,>=22.0\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ruff>=0.2.2\n",
      "  Downloading ruff-0.4.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in ./myenv/lib/python3.10/site-packages (from gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (2.2.2)\n",
      "Collecting tomlkit==0.12.0\n",
      "  Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in ./myenv/lib/python3.10/site-packages (from gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (3.1.4)\n",
      "Collecting ffmpy\n",
      "  Using cached ffmpy-0.3.2-py3-none-any.whl\n",
      "Collecting typer<1.0,>=0.12\n",
      "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 KB\u001b[0m \u001b[31m844.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib~=3.0 in ./myenv/lib/python3.10/site-packages (from gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (3.8.4)\n",
      "Collecting websockets<12.0,>=10.0\n",
      "  Using cached websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Collecting toolz\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: idna in ./myenv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (3.7)\n",
      "Collecting sniffio\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: certifi in ./myenv/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (2024.2.2)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Collecting anyio\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./myenv/lib/python3.10/site-packages (from jsonschema->rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./myenv/lib/python3.10/site-packages (from jsonschema->rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./myenv/lib/python3.10/site-packages (from jsonschema->rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./myenv/lib/python3.10/site-packages (from jsonschema->rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (0.18.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (4.51.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (3.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (2024.1)\n",
      "Collecting pydantic-core==2.18.2\n",
      "  Downloading pydantic_core-2.18.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting tokenizers<0.15,>=0.14\n",
      "  Using cached tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "INFO: pip is looking at multiple versions of semantic-version to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting semantic-version~=2.0\n",
      "  Using cached semantic_version-2.9.0-py2.py3-none-any.whl (15 kB)\n",
      "INFO: pip is looking at multiple versions of safetensors to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "INFO: pip is looking at multiple versions of ruff to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ruff>=0.2.2\n",
      "  Downloading ruff-0.4.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of regex to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.5.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.1/774.1 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting PyYAML>=5.1.0\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "INFO: pip is looking at multiple versions of python-multipart to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pydantic-core to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pydantic>=2.0\n",
      "  Downloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.9/407.9 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pandas<3.0,>=1.0\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "INFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "INFO: pip is looking at multiple versions of orjson to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting orjson~=3.0\n",
      "  Downloading orjson-3.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib~=3.0\n",
      "  Downloading matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting markupsafe~=2.0\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of jsonschema to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jsonschema\n",
      "  Using cached jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jinja2<4.0\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "INFO: pip is looking at multiple versions of importlib-resources to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting importlib-resources<7.0,>=1.3\n",
      "  Downloading importlib_resources-6.3.2-py3-none-any.whl (35 kB)\n",
      "INFO: pip is looking at multiple versions of httpcore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "  Using cached httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "  Using cached httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
      "  Using cached httpcore-1.0.0-py3-none-any.whl (76 kB)\n",
      "INFO: pip is looking at multiple versions of httpx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting httpx>=0.24.1\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "INFO: pip is looking at multiple versions of fsspec to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of altair to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting altair<6.0,>=4.2.0\n",
      "  Using cached altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "INFO: pip is looking at multiple versions of aiofiles to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiofiles<24.0,>=22.0\n",
      "  Using cached aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of tomlkit to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of gradio-client to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gradio\n",
      "  Downloading gradio-4.31.2-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading gradio-4.31.1-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading gradio-4.31.0-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==0.16.2\n",
      "  Downloading gradio_client-0.16.2-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading gradio-4.29.0-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==0.16.1\n",
      "  Downloading gradio_client-0.16.1-py3-none-any.whl (314 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.6/314.6 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading gradio-4.28.3-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==0.16.0\n",
      "  Downloading gradio_client-0.16.0-py3-none-any.whl (314 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.4/314.4 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading gradio-4.28.2-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading gradio-4.28.1-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tomlkit to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of gradio-client to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading gradio-4.28.0-py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading gradio-4.27.0-py3-none-any.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==0.15.1\n",
      "  Downloading gradio_client-0.15.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading gradio-4.26.0-py3-none-any.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Using cached gradio-4.25.0-py3-none-any.whl (17.1 MB)\n",
      "Collecting gradio-client==0.15.0\n",
      "  Using cached gradio_client-0.15.0-py3-none-any.whl (313 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.24.0-py3-none-any.whl (17.1 MB)\n",
      "Collecting gradio-client==0.14.0\n",
      "  Using cached gradio_client-0.14.0-py3-none-any.whl (312 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.23.0-py3-none-any.whl (17.1 MB)\n",
      "  Using cached gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
      "Collecting gradio-client==0.13.0\n",
      "  Using cached gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.21.0-py3-none-any.whl (17.0 MB)\n",
      "Collecting gradio-client==0.12.0\n",
      "  Using cached gradio_client-0.12.0-py3-none-any.whl (310 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.20.1-py3-none-any.whl (17.0 MB)\n",
      "Collecting gradio-client==0.11.0\n",
      "  Using cached gradio_client-0.11.0-py3-none-any.whl (308 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.20.0-py3-none-any.whl (17.0 MB)\n",
      "  Using cached gradio-4.19.2-py3-none-any.whl (16.9 MB)\n",
      "Collecting gradio-client==0.10.1\n",
      "  Using cached gradio_client-0.10.1-py3-none-any.whl (307 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.19.1-py3-none-any.whl (16.9 MB)\n",
      "Collecting gradio-client==0.10.0\n",
      "  Using cached gradio_client-0.10.0-py3-none-any.whl (307 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.19.0-py3-none-any.whl (16.9 MB)\n",
      "  Using cached gradio-4.18.0-py3-none-any.whl (16.8 MB)\n",
      "  Using cached gradio-4.17.0-py3-none-any.whl (16.7 MB)\n",
      "Collecting gradio-client==0.9.0\n",
      "  Using cached gradio_client-0.9.0-py3-none-any.whl (306 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.16.0-py3-none-any.whl (16.7 MB)\n",
      "Collecting gradio-client==0.8.1\n",
      "  Using cached gradio_client-0.8.1-py3-none-any.whl (305 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.15.0-py3-none-any.whl (16.6 MB)\n",
      "  Using cached gradio-4.14.0-py3-none-any.whl (16.6 MB)\n",
      "Collecting gradio-client==0.8.0\n",
      "  Using cached gradio_client-0.8.0-py3-none-any.whl (305 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.13.0-py3-none-any.whl (16.6 MB)\n",
      "  Using cached gradio-4.12.0-py3-none-any.whl (16.6 MB)\n",
      "  Using cached gradio-4.11.0-py3-none-any.whl (16.6 MB)\n",
      "Collecting gradio-client==0.7.3\n",
      "  Using cached gradio_client-0.7.3-py3-none-any.whl (304 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.10.0-py3-none-any.whl (16.6 MB)\n",
      "  Using cached gradio-4.9.1-py3-none-any.whl (16.6 MB)\n",
      "  Using cached gradio-4.9.0-py3-none-any.whl (16.6 MB)\n",
      "Collecting gradio-client==0.7.2\n",
      "  Using cached gradio_client-0.7.2-py3-none-any.whl (304 kB)\n",
      "Collecting gradio\n",
      "  Using cached gradio-4.8.0-py3-none-any.whl (16.5 MB)\n",
      "Collecting gradio-client==0.7.1\n",
      "  Using cached gradio_client-0.7.1-py3-none-any.whl (302 kB)\n",
      "Collecting huggingface-hub\n",
      "  Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.10/site-packages (from requests->transformers==4.35.0->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 5)) (3.3.2)\n",
      "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: click>=8.0.0 in ./myenv/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (8.1.7)\n",
      "Collecting rich>=10.11.0\n",
      "  Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1\n",
      "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 KB\u001b[0m \u001b[31m904.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting email_validator>=2.0.0\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Collecting fastapi-cli>=0.0.2\n",
      "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.10/site-packages (from imageio-ffmpeg->imageio[ffmpeg]->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 9)) (59.6.0)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: sympy in ./myenv/lib/python3.10/site-packages (from onnxruntime->rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (1.12)\n",
      "Collecting flatbuffers\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./myenv/lib/python3.10/site-packages (from pooch->rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (4.2.1)\n",
      "Collecting numba!=0.49.0\n",
      "  Using cached numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "Collecting lazy-loader>=0.4\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in ./myenv/lib/python3.10/site-packages (from scikit-image->rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (3.3)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Using cached tifffile-2024.5.10-py3-none-any.whl (225 kB)\n",
      "Collecting dnspython>=2.0.0\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llvmlite<0.43,>=0.42.0dev0\n",
      "  Using cached llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./myenv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (2.18.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./myenv/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 10)) (1.2.1)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting httptools>=0.5.0\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./myenv/lib/python3.10/site-packages (from sympy->onnxruntime->rembg->-r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt (line 7)) (1.3.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using legacy 'setup.py install' for torchmcubes, since package 'wheel' is not installed.\n",
      "Installing collected packages: torchmcubes, pydub, flatbuffers, ffmpy, websockets, uvloop, ujson, trimesh, toolz, tomlkit, tifffile, sniffio, shellingham, semantic-version, safetensors, regex, python-multipart, python-dotenv, pydantic-core, protobuf, Pillow, orjson, opencv-python-headless, mdurl, llvmlite, lazy-loader, importlib-resources, imageio-ffmpeg, humanfriendly, httptools, h11, einops, dnspython, annotated-types, aiofiles, uvicorn, pydantic, pooch, numba, markdown-it-py, imageio, huggingface-hub, httpcore, email_validator, coloredlogs, anyio, watchfiles, tokenizers, starlette, scikit-image, rich, pymatting, onnxruntime, httpx, typer, transformers, rembg, gradio-client, altair, fastapi-cli, fastapi, gradio\n",
      "  Running setup.py install for torchmcubes ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: trimesh\n",
      "    Found existing installation: trimesh 4.3.2\n",
      "    Uninstalling trimesh-4.3.2:\n",
      "      Successfully uninstalled trimesh-4.3.2\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: pillow 10.3.0\n",
      "    Uninstalling pillow-10.3.0:\n",
      "      Successfully uninstalled pillow-10.3.0\n",
      "  Attempting uninstall: einops\n",
      "    Found existing installation: einops 0.8.0\n",
      "    Uninstalling einops-0.8.0:\n",
      "      Successfully uninstalled einops-0.8.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.0\n",
      "    Uninstalling huggingface-hub-0.23.0:\n",
      "      Successfully uninstalled huggingface-hub-0.23.0\n",
      "Successfully installed Pillow-10.1.0 aiofiles-23.2.1 altair-5.3.0 annotated-types-0.6.0 anyio-4.3.0 coloredlogs-15.0.1 dnspython-2.6.1 einops-0.7.0 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.3 ffmpy-0.3.2 flatbuffers-24.3.25 gradio-4.8.0 gradio-client-0.7.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.17.3 humanfriendly-10.0 imageio-2.34.1 imageio-ffmpeg-0.4.9 importlib-resources-6.4.0 lazy-loader-0.4 llvmlite-0.42.0 markdown-it-py-3.0.0 mdurl-0.1.2 numba-0.59.1 onnxruntime-1.17.3 opencv-python-headless-4.9.0.80 orjson-3.10.3 pooch-1.8.1 protobuf-5.26.1 pydantic-2.7.1 pydantic-core-2.18.2 pydub-0.25.1 pymatting-1.1.12 python-dotenv-1.0.1 python-multipart-0.0.9 regex-2024.5.15 rembg-2.0.56 rich-13.7.1 safetensors-0.4.3 scikit-image-0.23.2 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.37.2 tifffile-2024.5.10 tokenizers-0.14.1 tomlkit-0.12.0 toolz-0.12.1 torchmcubes-0.1.0 transformers-4.35.0 trimesh-4.0.5 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-11.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Replace 'path/to/requirements.txt' with the actual path to your requirements.txt file\n",
    "%pip install -r /home/aalab/Desktop/tripoFT/TripoSR/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the TSR class\n",
    "from tsr.system import TSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tsr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtsr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msystem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSR \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the pre-trained model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtsr\u001b[49m(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Modify the model if necessary\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# model.fc = nn.Linear(model.fc.in_features, num_classes)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Move model to GPU if available\u001b[39;00m\n\u001b[1;32m     14\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tsr' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming tripoSR is a class in your project, replace with actual import\n",
    "from tsr.system import TSR \n",
    "\n",
    "# Load the pre-trained model\n",
    "model = tsr(pretrained=True)\n",
    "\n",
    "# Modify the model if necessary\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()  # Example, use appropriate loss for your task\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for vertices, faces in train_loader:\n",
    "            vertices, faces = vertices.to(device), faces.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(vertices)\n",
    "            loss = criterion(outputs, faces)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * vertices.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss}')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for vertices, faces in val_loader:\n",
    "                vertices, faces = vertices.to(device), faces.to(device)\n",
    "                \n",
    "                outputs = model(vertices)\n",
    "                loss = criterion(outputs, faces)\n",
    "                \n",
    "                val_loss += loss.item() * vertices.size(0)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        print(f'Validation Loss: {val_loss}')\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=25)\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for vertices, faces in test_loader:\n",
    "            vertices, faces = vertices.to(device), faces.to(device)\n",
    "            \n",
    "            outputs = model(vertices)\n",
    "            loss = criterion(outputs, faces)\n",
    "            \n",
    "            test_loss += loss.item() * vertices.size(0)\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(model, test_loader, criterion)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "# torch.save(model.state_dict(), 'fine_tuned_tripoSR.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
